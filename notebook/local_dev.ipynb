{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\User\\\\Python\\\\pool_management_system'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: ./artifact/original_data/classes.txt\n"
     ]
    }
   ],
   "source": [
    "from src.constants import CONFIG_FILE_PATH\n",
    "from src.utils.utils import  read_yaml, write_yaml\n",
    "from src.utils.preprocess_utils import  create_yolo_data_yaml\n",
    "\n",
    "config = read_yaml(CONFIG_FILE_PATH)\n",
    "\n",
    "\n",
    "CLASSES_TXT_PATH  = config[\"CLASSES_TXT_PATH\"]\n",
    "DATA_YAML_PATH    = config[\"MODEL\"][\"DATA_YAML_PATH\"]\n",
    "DATA_PATH = './data'\n",
    "create_yolo_data_yaml(DATA_PATH, CLASSES_TXT_PATH, DATA_YAML_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Chairs: 105\n",
      "Occupied Chairs: 71\n"
     ]
    }
   ],
   "source": [
    "label_dir = \"data/labels\"\n",
    "\n",
    "empty_count = 0\n",
    "occupied_count = 0\n",
    "\n",
    "for label_file in os.listdir(label_dir):\n",
    "    with open(os.path.join(label_dir, label_file), \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            class_id = line.split()[0]  # First number is class ID\n",
    "            if class_id == \"0\":\n",
    "                empty_count += 1\n",
    "            elif class_id == \"1\":\n",
    "                occupied_count += 1\n",
    "\n",
    "print(f\"Empty Chairs: {empty_count}\")\n",
    "print(f\"Occupied Chairs: {occupied_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING  imgsz=[2750, 4133] must be multiple of max stride 32, updating to [2752, 4160]\n",
      "0: 2752x4160 1 occupied-chair, 10 unoccupied-chairs, 51172.3ms\n",
      "Speed: 225.4ms preprocess, 51172.3ms inference, 33.2ms postprocess per image at shape (1, 3, 2752, 4160)\n"
     ]
    }
   ],
   "source": [
    "# Load your trained YOLOv8 model\n",
    "model = YOLO(\"model/my_model.pt\")  # Update path if needed\n",
    "\n",
    "# Load a test image\n",
    "image_path = \"test_images/side_3.jpg\"  \n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Run inference\n",
    "results = model(image, imgsz=image.shape[:2])\n",
    "\n",
    "# Draw detections on the image (manually, no cropping)\n",
    "for r in results:\n",
    "    for box in r.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates\n",
    "        class_id = int(box.cls[0])  # Class index\n",
    "        confidence = box.conf[0]  # Confidence score\n",
    "        \n",
    "        # Class names (ensure these match your training labels)\n",
    "        class_names = [\"empty_chair\", \"occupied_chair\"]\n",
    "        label = f\"{class_names[class_id]} {confidence:.2f}\"\n",
    "        \n",
    "        # Draw bounding box and label\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(image, label, (x1, y1 - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Save and display result\n",
    "output_path = \"output/detected_pool_test.jpg\"\n",
    "cv2.imwrite(output_path, image)\n",
    "\n",
    "cv2.imshow(\"YOLOv8 Detection\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model = YOLO(\"runs/train/exp/weights/best.pt\")  # Update path if needed\n",
    "\n",
    "# Load the test video\n",
    "video_path = \"test_videos/pool_video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get video properties\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define video writer to save output\n",
    "out = cv2.VideoWriter(\"output/pool_output.mp4\", \n",
    "                      cv2.VideoWriter_fourcc(*'mp4v'), fps, \n",
    "                      (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLOv8 inference on the frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # Draw detections on the frame\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # Bounding box coordinates\n",
    "            class_id = int(box.cls[0])  # Class index\n",
    "            confidence = box.conf[0]  # Confidence score\n",
    "            \n",
    "            # Class names (ensure this matches your trained labels)\n",
    "            class_names = [\"empty_chair\", \"occupied_chair\"]\n",
    "            label = f\"{class_names[class_id]} {confidence:.2f}\"\n",
    "            \n",
    "            # Draw bounding box and label\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Write frame to output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Show frame (optional, remove for headless execution)\n",
    "    cv2.imshow(\"YOLOv8 Pool Chair Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from fastapi import FastAPI, File, UploadFile, Request, Response, Query\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from starlette.responses import RedirectResponse\n",
    "from fastapi.templating import Jinja2Templates\n",
    "import tempfile\n",
    "from src.scripts.inference import load_model, read_image, run_inference_on_video\n",
    "import cv2\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# FastAPI app setup\n",
    "app = FastAPI(title=\"YOLOv8 Inference API\", version=\"1.0\")\n",
    "\n",
    "# Enable CORS for frontend access\n",
    "origins = [\"*\"]\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"]\n",
    ")\n",
    "\n",
    "# Set up templates\n",
    "templates = Jinja2Templates(directory=\"templates\")\n",
    "\n",
    "# Model path\n",
    "MODEL_PATH = Path(os.getenv(\"MODEL_PATH\", \"final_model/train/weights/best.pt\")).resolve()\n",
    "logger.info(f\"Using YOLO model from: {MODEL_PATH}\")\n",
    "\n",
    "# Load YOLO model at startup\n",
    "try:\n",
    "    model = load_model(str(MODEL_PATH))\n",
    "    logger.info(\"YOLO model loaded successfully\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Model loading failed: {e}\")\n",
    "    model = None  # Prevent crashes if model isn't found\n",
    "\n",
    "@app.get(\"/\", tags=[\"root\"])\n",
    "async def index():\n",
    "    \"\"\"Redirects to API docs.\"\"\"\n",
    "    return RedirectResponse(url=\"/docs\")\n",
    "\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(\n",
    "    request: Request,\n",
    "    file: UploadFile = File(...),\n",
    "    conf_threshold: float = 0.5 \n",
    "):\n",
    "    \"\"\"\n",
    "    Accepts an image file, runs YOLO inference, and returns an HTML page with the processed image.\n",
    "    \n",
    "    Query Parameters:\n",
    "    - `conf_threshold` (float, default=0.5): Minimum confidence score to display detections.\n",
    "\n",
    "    Returns:\n",
    "    - An HTML page displaying the processed image and detected objects.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        return {\"error\": \"ðŸš¨ Model is not loaded. Check logs for issues.\"}\n",
    "\n",
    "    try:\n",
    "        # Read and process image\n",
    "        image_bytes = await file.read()\n",
    "        processed_img = read_image(model, image_bytes, conf_threshold=conf_threshold)\n",
    "\n",
    "        # Encode the processed image as JPEG\n",
    "        _, encoded_image = cv2.imencode('.jpg', processed_img)\n",
    "\n",
    "        return Response(content=encoded_image.tobytes(), media_type=\"image/jpeg\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Inference failed: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "@app.post(\"/predict/video/\")\n",
    "async def predict_video(\n",
    "    file: UploadFile = File(...),\n",
    "    conf_threshold: float = Query(0.5, description=\"Confidence threshold for detections\")\n",
    "):\n",
    "    \"\"\"\n",
    "    Accepts a video file, runs YOLO inference frame-by-frame,\n",
    "    and returns the processed video as a response.\n",
    "\n",
    "    Query Parameters:\n",
    "    - `conf_threshold` (float, default=0.5): Minimum confidence to display detections.\n",
    "    \n",
    "    Returns:\n",
    "    - A video (mp4) with bounding boxes drawn on each frame.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        return {\"error\": \"Model is not loaded. Check logs for issues.\"}\n",
    "    \n",
    "    try:\n",
    "        # Save the uploaded video to a temporary file\n",
    "        temp_input = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
    "        temp_input_path = temp_input.name\n",
    "        temp_input.close()\n",
    "        with open(temp_input_path, \"wb\") as f:\n",
    "            f.write(await file.read())\n",
    "        logger.info(f\"Video saved to temp file: {temp_input_path}\")\n",
    "\n",
    "        # Create a temporary file for the processed output video\n",
    "        temp_output = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
    "        temp_output_path = temp_output.name\n",
    "        temp_output.close()\n",
    "\n",
    "        # Run inference on video: this function writes processed frames to temp_output_path.\n",
    "        run_inference_on_video(model, temp_input_path, conf_threshold=conf_threshold, imgsz=640)\n",
    "\n",
    "        # Read the processed video and return it as the response\n",
    "        with open(temp_output_path, \"rb\") as processed_video:\n",
    "            video_bytes = processed_video.read()\n",
    "\n",
    "        return Response(content=video_bytes, media_type=\"video/mp4\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Video inference failed: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
